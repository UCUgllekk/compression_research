{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Huffman_Compression:\n",
    "    \"\"\"\n",
    "    Class for compression and decompression, uses\n",
    "    Huffman algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes dict of symbols and name of algorithm\n",
    "        \"\"\"\n",
    "        self.main_dict = {}\n",
    "        self.name = 'huffm'\n",
    "    def generate_code(self, node: 'Node', coding: str) -> None:\n",
    "        \"\"\"\n",
    "        Generates all codings of symbols\n",
    "        \"\"\"\n",
    "        if node.char is not None:\n",
    "            char = node.char\n",
    "            code = coding\n",
    "            self.main_dict[char] = code\n",
    "        else:\n",
    "            self.generate_code(node.left_child, coding + '0')\n",
    "            self.generate_code(node.right_child, coding + '1')\n",
    "\n",
    "    def encode(self, text: str) -> tuple[str, dict[bytes, str]]:\n",
    "        \"\"\"\n",
    "        Encoder functions, returns sequence of bits and dict of all codings.\n",
    "        \"\"\"\n",
    "        frequency = self.frequency(text)\n",
    "        nodes = []\n",
    "        for (char, freq) in frequency:\n",
    "            nodes.append(Node(freq, char))   \n",
    "        while len(nodes) > 1:\n",
    "            first_lowest = nodes[0]\n",
    "            second_lowest = nodes[1]\n",
    "            min_freq = nodes.pop(0).freq + nodes.pop(0).freq\n",
    "            new_node = Node(min_freq)\n",
    "            new_node.left_child = first_lowest\n",
    "            new_node.right_child = second_lowest\n",
    "            nodes.append(new_node)\n",
    "            nodes = sorted(nodes, key= lambda x: x.freq)\n",
    "        self.generate_code(nodes[0], '')\n",
    "        coded_str = ''\n",
    "        for i in text:\n",
    "            coded_str += self.main_dict[i]\n",
    "        return (coded_str, self.main_dict)    \n",
    "    def frequency(self, text: bytes):\n",
    "        \"\"\"\n",
    "        Function that helps calculate the frequency of all symbols\n",
    "        \"\"\"\n",
    "        freq = {}\n",
    "        for char in text:\n",
    "            if char not in freq:\n",
    "                freq[char] = 1\n",
    "            else:\n",
    "                freq[char] += 1\n",
    "        return sorted(freq.items(), key= lambda x: x[1])\n",
    "    \n",
    "    def decode(self, code: str, coding_dict: dict[bytes, str]) -> bytes:\n",
    "        \"\"\"\n",
    "        Decodes files\n",
    "        \"\"\"\n",
    "        decoded_str = bytearray()\n",
    "        coding_dict = {i : j for j, i in coding_dict.items()}\n",
    "        while code:\n",
    "            for cd in coding_dict:\n",
    "                if code.startswith(cd):\n",
    "                    decoded_str += bytes([coding_dict[cd]])\n",
    "                    code = code[len(cd):]\n",
    "        return decoded_str\n",
    "    def add_fictious_bins(self, bin_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Adds fictious bits in the end, so that sequence\n",
    "        can be fully transformed into bytes. Also adds\n",
    "        byte representaion of nums of added bits, so that \n",
    "        correct number will be removed in decompression \n",
    "        \"\"\"\n",
    "        fictious = (8 - len(bin_str) % 8)\n",
    "        for i in range(fictious):\n",
    "            bin_str += '0'\n",
    "        fictious_info_secret = \"{0:08b}\".format(fictious)\n",
    "        return fictious_info_secret + bin_str\n",
    "    \n",
    "    def remove_fictious(self, bin_str: str):\n",
    "        \"\"\"\n",
    "        Removes fictious bits\n",
    "        \"\"\"\n",
    "        fict_info = bin_str[:8]\n",
    "        fict_info = int(fict_info, 2)\n",
    "        bin_str = bin_str[8:]\n",
    "        return bin_str[:-1 * fict_info]\n",
    "    \n",
    "    def compress(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Compresses files, uses encode func to generate \n",
    "        sequence of bits\n",
    "        \"\"\"\n",
    "        with open(path, 'rb') as file:\n",
    "            image = file.read()\n",
    "        encoded_data, encoded_dict = self.encode(image)\n",
    "        file_type = path[len(path)-3:]\n",
    "        encoded_data = self.add_fictious_bins(encoded_data)\n",
    "        b = bytearray()\n",
    "        for i in range(0, len(encoded_data), 8):\n",
    "            byte = encoded_data[i:i+8]\n",
    "            b.append(int(byte, 2))\n",
    "        with open((path:=path[:-3]+self.name.lower()), 'wb') as file:\n",
    "            file.write(bytes(b))\n",
    "        return path, encoded_dict, file_type\n",
    "    \n",
    "    def decompress(self, file_mix: tuple[str, dict, str]) -> None:\n",
    "        \"\"\"\n",
    "        Removes fictious bits and decompresses files.\n",
    "        \"\"\"\n",
    "        output_path = file_mix[0][:-4] + '_decoded.' + file_mix[2]\n",
    "        with open(file_mix[0], 'rb') as file:\n",
    "            bit_str = ''\n",
    "            byte = file.read(1)\n",
    "            while len(byte) > 0:\n",
    "                byte = ord(byte)\n",
    "                bits = bin(byte)[2:].rjust(8, '0')\n",
    "                bit_str += bits\n",
    "                byte = file.read(1)\n",
    "            bit_str = self.remove_fictious(bit_str)\n",
    "            decompr = self.decode(bit_str, file_mix[1])\n",
    "        with open(output_path, 'wb') as writte:\n",
    "            writte.write(bytes(decompr))\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Class Node, used for Huffman algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, freq: bytes, char = None) -> None:\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "    def __repr__(self) -> str:\n",
    "        return f'(\"{self.char}\", {self.freq})'\n",
    "    \n",
    "huffman = Huffman_Compression()\n",
    "compressed = huffman.compress('C:\\\\Users\\migel\\\\PythonProjects\\\\compression_research\\\\files_to_test\\\\txt_test_3.txt')\n",
    "huffman.decompress(compressed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZ77 / LZ78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lz77(data):\n",
    "    ...\n",
    "\n",
    "#or\n",
    "\n",
    "def lz78(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZW:\n",
    "    name = 'lzw'\n",
    "    def encode(self, data: bytes) -> tuple[bytes, list]:\n",
    "        '''LZW encoding'''\n",
    "        output = []\n",
    "        w = b''\n",
    "        dictionary = {bytes([i]): i for i in range(256)}\n",
    "        for byte in data:\n",
    "            byte = bytes([byte])\n",
    "            wc = w + byte\n",
    "            if wc in dictionary:\n",
    "                w = wc\n",
    "            else:\n",
    "                output.append(dictionary[w])\n",
    "                dictionary[wc] = len(dictionary)\n",
    "                w = byte\n",
    "        if w:\n",
    "            output.append(dictionary[w])\n",
    "        return output, {bytes([i]): i for i in range(256)}\n",
    "\n",
    "    def decode(self, code: bytes, coding_dict: dict) -> bytes:\n",
    "        '''LZW decoding'''\n",
    "        coding_dict = {v:k for k,v in coding_dict.items()}\n",
    "        string = coding_dict[code[0]]\n",
    "        output = bytearray()\n",
    "        output += string\n",
    "        for i in range(1, len(code)):\n",
    "            new = code[i]\n",
    "            if new not in coding_dict:\n",
    "                entry = string + string[:1]\n",
    "            else:\n",
    "                entry = coding_dict[new]\n",
    "            output += entry\n",
    "            coding_dict[len(coding_dict)] = string + entry[:1]\n",
    "            string = entry\n",
    "        return bytes(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deflate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflate(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(path:str, compress_algorithm:object):\n",
    "    with open(path, 'rb') as file:\n",
    "        image = file.read()\n",
    "    encoded_data, encoded_dict = compress_algorithm.encode(image)\n",
    "    file_type = path[::-1].split('.', maxsplit=1)[0][::-1]\n",
    "    file_path = path[::-1].split('.', maxsplit=1)[1][::-1]+'.'+compress_algorithm.name.lower()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for value in encoded_data:\n",
    "            file.write(value.to_bytes(3, byteorder='little'))\n",
    "    return file_path, file_type, compress_algorithm, encoded_dict\n",
    "\n",
    "def decoding(path:str, f_type:str, compress_algorithm:object, start_dict:dict = None):\n",
    "    with open(path, 'rb') as file:\n",
    "        encoded_data = []\n",
    "        while (byte := file.read(3)):\n",
    "            encoded_data.append(int.from_bytes(byte, byteorder='little'))\n",
    "    if start_dict:\n",
    "        decoded = compress_algorithm.decode(encoded_data, start_dict)\n",
    "    else:\n",
    "        decoded = compress_algorithm.decode(encoded_data)\n",
    "    file_path = path[::-1].split('.', maxsplit=1)[1][::-1]+'_decoded.'+f_type\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
