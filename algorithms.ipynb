{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Huffman_Compression:\n",
    "    \"\"\"\n",
    "    Class for compression and decompression, uses\n",
    "    Huffman algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes dict of symbols and name of algorithm\n",
    "        \"\"\"\n",
    "        self.main_dict = {}\n",
    "        self.name = 'huffm'\n",
    "    def generate_code(self, node: 'Node', coding: str) -> None:\n",
    "        \"\"\"\n",
    "        Generates all codings of symbols\n",
    "        \"\"\"\n",
    "        if node.char is not None:\n",
    "            char = node.char\n",
    "            code = coding\n",
    "            self.main_dict[char] = code\n",
    "        else:\n",
    "            self.generate_code(node.left_child, coding + '0')\n",
    "            self.generate_code(node.right_child, coding + '1')\n",
    "\n",
    "    def encode(self, text: str) -> tuple[str, dict[bytes, str]]:\n",
    "        \"\"\"\n",
    "        Encoder functions, returns sequence of bits and dict of all codings.\n",
    "        \"\"\"\n",
    "        frequency = self.frequency(text)\n",
    "        nodes = []\n",
    "        for (char, freq) in frequency:\n",
    "            nodes.append(Node(freq, char))   \n",
    "        while len(nodes) > 1:\n",
    "            first_lowest = nodes[0]\n",
    "            second_lowest = nodes[1]\n",
    "            min_freq = nodes.pop(0).freq + nodes.pop(0).freq\n",
    "            new_node = Node(min_freq)\n",
    "            new_node.left_child = first_lowest\n",
    "            new_node.right_child = second_lowest\n",
    "            nodes.append(new_node)\n",
    "            nodes = sorted(nodes, key= lambda x: x.freq)\n",
    "        self.generate_code(nodes[0], '')\n",
    "        coded_str = ''\n",
    "        for i in text:\n",
    "            coded_str += self.main_dict[i]\n",
    "        return (coded_str, self.main_dict)    \n",
    "    def frequency(self, text: bytes):\n",
    "        \"\"\"\n",
    "        Function that helps calculate the frequency of all symbols\n",
    "        \"\"\"\n",
    "        freq = {}\n",
    "        for char in text:\n",
    "            if char not in freq:\n",
    "                freq[char] = 1\n",
    "            else:\n",
    "                freq[char] += 1\n",
    "        return sorted(freq.items(), key= lambda x: x[1])\n",
    "    \n",
    "    def decode(self, code: str, coding_dict: dict[bytes, str]) -> bytes:\n",
    "        \"\"\"\n",
    "        Decodes files\n",
    "        \"\"\"\n",
    "        decoded_str = bytearray()\n",
    "        coding_dict = {i : j for j, i in coding_dict.items()}\n",
    "        buffer = ''\n",
    "        for bit in code:\n",
    "            buffer += bit\n",
    "            if buffer in coding_dict:\n",
    "                decoded_str += bytes([coding_dict[buffer]])\n",
    "                buffer = ''\n",
    "        return decoded_str\n",
    "    def add_fictious_bins(self, bin_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Adds fictious bits in the end, so that sequence\n",
    "        can be fully transformed into bytes. Also adds\n",
    "        byte representaion of nums of added bits, so that \n",
    "        correct number will be removed in decompression \n",
    "        \"\"\"\n",
    "        fictious = (8 - len(bin_str) % 8)\n",
    "        for i in range(fictious):\n",
    "            bin_str += '0'\n",
    "        fictious_info_secret = \"{0:08b}\".format(fictious)\n",
    "        return fictious_info_secret + bin_str\n",
    "    \n",
    "    def remove_fictious(self, bin_str: str):\n",
    "        \"\"\"\n",
    "        Removes fictious bits\n",
    "        \"\"\"\n",
    "        fict_info = bin_str[:8]\n",
    "        fict_info = int(fict_info, 2)\n",
    "        bin_str = bin_str[8:]\n",
    "        return bin_str[:-1 * fict_info]\n",
    "    \n",
    "    def dict_to_bytes(self, dictt: dict):\n",
    "        \"\"\"\n",
    "        Converts dicts to bytes\n",
    "        \"\"\"\n",
    "        keys = bytes(dictt.keys())\n",
    "        values = bytes(':'.join(dictt.values()), encoding='utf-8')\n",
    "        data = keys + b'separ' + values + b'end'\n",
    "        return data\n",
    "    \n",
    "    def dict_from_bytes(self, data: bytes):\n",
    "        \"\"\"\n",
    "        Converts dict(expressed by bytes) to dict\n",
    "        \"\"\"\n",
    "        data = data.split(b'separ')\n",
    "        keys = list(data[0])\n",
    "        values = list(data[1].decode('utf-8').split(':'))\n",
    "        reconstructed_dict = {}\n",
    "        for i in range(len(keys)):\n",
    "            key = keys[i]\n",
    "            value = values[i]\n",
    "            reconstructed_dict[key] = value\n",
    "        return reconstructed_dict\n",
    "\n",
    "    def compress(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Compresses files, uses encode func to generate \n",
    "        sequence of bits\n",
    "        \"\"\"\n",
    "        with open(path, 'rb') as file:\n",
    "            image = file.read()\n",
    "        encoded_data, encoded_dict = self.encode(image)\n",
    "        encoded_data = self.add_fictious_bins(encoded_data)\n",
    "        b = bytearray()\n",
    "        for i in range(0, len(encoded_data), 8):\n",
    "            byte = encoded_data[i:i+8]\n",
    "            b.append(int(byte, 2))\n",
    "        new_path = f'{path}.{self.name}'\n",
    "        with open(new_path, 'wb') as file:\n",
    "            file.write(self.dict_to_bytes(encoded_dict))\n",
    "            file.write(bytes(b))\n",
    "        return new_path\n",
    "    \n",
    "    def decompress(self, file: tuple[str, dict, str]) -> None:\n",
    "        \"\"\"\n",
    "        Removes fictious bits and decompresses files.\n",
    "        \"\"\"\n",
    "        o_u = os.path.splitext(file)\n",
    "        f_f = os.path.splitext(o_u[0])\n",
    "        output_path = f_f[0] + '_decoded' + f_f[1]\n",
    "        with open(file, 'rb') as file:\n",
    "            file = file.read()\n",
    "            encoded_dict = file[:file.index(b'end')]\n",
    "            file = file[file.index(b'end')+3:]\n",
    "            encoded_dict = self.dict_from_bytes(encoded_dict)\n",
    "            bit_str = ''\n",
    "            for byte in file:\n",
    "                bits = bin(byte)[2:].rjust(8, '0')\n",
    "                bit_str += bits\n",
    "            bit_str = self.remove_fictious(bit_str)\n",
    "            decompr = self.decode(bit_str, encoded_dict)\n",
    "        with open(output_path, 'wb') as writte:\n",
    "            writte.write(bytes(decompr))\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Class Node, used for Huffman algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, freq: bytes, char = None) -> None:\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "    def __repr__(self) -> str:\n",
    "        return f'(\"{self.char}\", {self.freq})'\n",
    "    \n",
    "huffman = Huffman_Compression()\n",
    "huffman.compress('C:\\\\Users\\migel\\\\PythonProjects\\\\compression_research\\\\files_to_test\\\\test_huff.txt')\n",
    "huffman.decompress('C:\\\\Users\\migel\\\\PythonProjects\\\\compression_research\\\\files_to_test\\\\test_huff.txt.huffm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\migel\\\\PythonProjects\\\\compression_research\\\\files_to_test\\\\test_huff.TXT', 'r') as file:\n",
    "    file1 = file.read()\n",
    "with open('C:\\\\Users\\\\migel\\\\PythonProjects\\\\compression_research\\\\files_to_test\\\\test_huff_decoded.TXT', 'r') as file2:\n",
    "    file2 = file2.read()\n",
    "print(file1 == file2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZ77 / LZ78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lz77(data):\n",
    "    ...\n",
    "\n",
    "#or\n",
    "\n",
    "def lz78(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZW:\n",
    "    name = 'lzw'\n",
    "    def encode(self, data: bytes) -> tuple[bytes, list]:\n",
    "        '''LZW encoding'''\n",
    "        output = []\n",
    "        w = b''\n",
    "        dictionary = {bytes([i]): i for i in range(256)}\n",
    "        for byte in data:\n",
    "            byte = bytes([byte])\n",
    "            wc = w + byte\n",
    "            if wc in dictionary:\n",
    "                w = wc\n",
    "            else:\n",
    "                output.append(dictionary[w])\n",
    "                dictionary[wc] = len(dictionary)\n",
    "                w = byte\n",
    "        if w:\n",
    "            output.append(dictionary[w])\n",
    "        return output, {bytes([i]): i for i in range(256)}\n",
    "\n",
    "    def decode(self, code: bytes, coding_dict: dict) -> bytes:\n",
    "        '''LZW decoding'''\n",
    "        coding_dict = {v:k for k,v in coding_dict.items()}\n",
    "        string = coding_dict[code[0]]\n",
    "        output = bytearray()\n",
    "        output += string\n",
    "        for i in range(1, len(code)):\n",
    "            new = code[i]\n",
    "            if new not in coding_dict:\n",
    "                entry = string + string[:1]\n",
    "            else:\n",
    "                entry = coding_dict[new]\n",
    "            output += entry\n",
    "            coding_dict[len(coding_dict)] = string + entry[:1]\n",
    "            string = entry\n",
    "        return bytes(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deflate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflate(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(path:str, compress_algorithm:object):\n",
    "    with open(path, 'rb') as file:\n",
    "        image = file.read()\n",
    "    encoded_data, encoded_dict = compress_algorithm.encode(image)\n",
    "    file_type = path[::-1].split('.', maxsplit=1)[0][::-1]\n",
    "    file_path = path[::-1].split('.', maxsplit=1)[1][::-1]+'.'+compress_algorithm.name.lower()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for value in encoded_data:\n",
    "            file.write(value.to_bytes(3, byteorder='little'))\n",
    "    return file_path, file_type, compress_algorithm, encoded_dict\n",
    "\n",
    "def decoding(path:str, f_type:str, compress_algorithm:object, start_dict:dict = None):\n",
    "    with open(path, 'rb') as file:\n",
    "        encoded_data = []\n",
    "        while (byte := file.read(3)):\n",
    "            encoded_data.append(int.from_bytes(byte, byteorder='little'))\n",
    "    if start_dict:\n",
    "        decoded = compress_algorithm.decode(encoded_data, start_dict)\n",
    "    else:\n",
    "        decoded = compress_algorithm.decode(encoded_data)\n",
    "    file_path = path[::-1].split('.', maxsplit=1)[1][::-1]+'_decoded.'+f_type\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
