{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZ77 / LZ78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lz77(data):\n",
    "    ...\n",
    "\n",
    "#or\n",
    "\n",
    "def lz78(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZW:\n",
    "    name = 'lzw'\n",
    "    def encode(self, data: bytes) -> tuple[bytes, list]:\n",
    "        '''LZW encoding'''\n",
    "        output = []\n",
    "        w = b''\n",
    "        start_dictionary = {bytes([i]): i for i in range(256)}\n",
    "        new_dictionary = start_dictionary.copy()\n",
    "        for byte in data:\n",
    "            byte = bytes([byte])\n",
    "            if w + byte in new_dictionary:\n",
    "                w += byte\n",
    "            else:\n",
    "                new_dictionary[w + byte] = len(new_dictionary)\n",
    "                output.append(new_dictionary[w])\n",
    "                w = byte\n",
    "        output.append(new_dictionary[w])\n",
    "        return output, start_dictionary\n",
    "\n",
    "    def decode(self, code: bytes, coding_dict: dict) -> bytes:\n",
    "        '''LZW decoding'''\n",
    "        coding_dict = {v:k for k,v in coding_dict.items()}\n",
    "        string = coding_dict[code[0]]\n",
    "        output = bytearray()\n",
    "        output += string\n",
    "        for i in range(1, len(code)):\n",
    "            new = code[i]\n",
    "            if new not in coding_dict:\n",
    "                entry = string + string[0:1]\n",
    "            else:\n",
    "                entry = coding_dict[new]\n",
    "            output += entry\n",
    "            coding_dict[len(coding_dict)] = string + entry[0:1]\n",
    "            string = entry\n",
    "        return bytes(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deflate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflate(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lzw = LZW()\n",
    "def encoding(path:str, compress_algorithm:object):\n",
    "    with open(path, 'rb') as file:\n",
    "        image = file.read()\n",
    "    encoded_data, encoded_dict = compress_algorithm.encode(image)\n",
    "    file_type = path[::-1].split('.', maxsplit=1)[0][::-1]\n",
    "    file_path = path[::-1].split('.', maxsplit=1)[1][::-1]+'.'+compress_algorithm.name.lower()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for value in encoded_data:\n",
    "            file.write(value.to_bytes(4, byteorder='big'))\n",
    "    return file_path, encoded_dict, file_type, compress_algorithm\n",
    "\n",
    "def decoding(path:str, start_dict:dict, f_type:str, compress_algorithm:object):\n",
    "    with open(path, 'rb') as file:\n",
    "        encoded_data = []\n",
    "        while (byte := file.read(4)):\n",
    "            encoded_data.append(int.from_bytes(byte, byteorder='big'))\n",
    "    decoded = compress_algorithm.decode(encoded_data, start_dict)\n",
    "    file_path = path[::-1].split('.', maxsplit=1)[1][::-1]+'_decoded.'+f_type\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/test_1.txt', lzw)\n",
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/bible.txt', lzw)\n",
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/bigfile.txt', lzw)\n",
    "enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/lorem.txt', lzw)\n",
    "\n",
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/E.coli', lzw)\n",
    "\n",
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/Parasyte_ The Grey _ Official Trailer _ Netflix.mp4', lzw)\n",
    "\n",
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/mixkit-fast-rocket-whoosh-1714.wav', lzw)\n",
    "\n",
    "# enc = encoding('/home/gllekk/all_the_code/default/DISCRETE/compression_research/img_test_1.png', lzw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec = decoding(enc[0], enc[1], enc[2], enc[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
